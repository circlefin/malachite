name: QA

on:
  workflow_dispatch:
    inputs:
      setup:
        description: "Deployment setup:"
        required: true
        default: "north-america"
        type: choice
        options: [global, north-america]
      expr_duration:
        description: "Experiment duration (in minutes)"
        required: true
        default: "15"
        type: choice
        options: ["15", "20", "30"]
      branch:
        description: "Git branch or tag to use"
        required: true
        default: "main"
      publish:
        description: "Publish results to the Malachite website?"
        required: false
        default: "false"
        type: choice
        options: ["true", "false"]
      runs:
        description: "Number of times to repeat the experiment"
        required: false
        default: "1"
        type: choice
        options: ["1", "2", "3", "4", "5"]

jobs:
  run-malachite-do:
    runs-on: ubuntu-latest
    env:
      TF_VAR_do_token: "${{ secrets.DO_TOKEN }}"
      TF_VAR_ssh_keys: '["${{ secrets.DO_SSH_FINGERPRINT }}"]'
      EXPR_SETUP: "${{ github.event.inputs.setup }}"
      EXPR_DURATION_MINUTES: "${{ github.event.inputs.expr_duration }}"
      BRANCH: "${{ github.event.inputs.branch }}"
      PUBLISH: "${{ github.event.inputs.publish }}"
      RUNS: "${{ github.event.inputs.runs }}"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ env.BRANCH }}

      - name: Set up SSH agent
        uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.DO_SSH_KEY }}

      - name: Install dependencies
        run: |
          sudo apt-get update -qq && sudo apt-get install -y pssh jq python3 python3-pip
          sudo ln -sf /usr/bin/parallel-ssh /usr/bin/pssh
          pip install --quiet --no-cache-dir pandas

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.10.5

      - name: Set node regions based on setup
        run: |
          if [[ "$EXPR_SETUP" == "global" ]]; then
            echo "TF_VAR_nyc1=2" >> $GITHUB_ENV
            echo "TF_VAR_nyc3=2" >> $GITHUB_ENV
            echo "TF_VAR_ams3=2" >> $GITHUB_ENV
            echo "TF_VAR_blr1=2" >> $GITHUB_ENV
            echo "TF_VAR_fra1=2" >> $GITHUB_ENV
            echo "TF_VAR_lon1=2" >> $GITHUB_ENV
            echo "TF_VAR_sfo3=2" >> $GITHUB_ENV
            echo "TF_VAR_sgp1=2" >> $GITHUB_ENV
            echo "TF_VAR_syd1=2" >> $GITHUB_ENV
            echo "TF_VAR_tor1=2" >> $GITHUB_ENV
          elif [[ "$EXPR_SETUP" == "north-america" ]]; then
            echo "TF_VAR_nyc1=1" >> $GITHUB_ENV
            echo "TF_VAR_nyc3=1" >> $GITHUB_ENV
            echo "TF_VAR_tor1=1" >> $GITHUB_ENV
            echo "TF_VAR_sfo3=1" >> $GITHUB_ENV
          else
            echo "Invalid EXPR_SETUP: $EXPR_SETUP"
            exit 1
          fi

      - name: Define experiment metadata
        id: vars
        run: |
          if [[ "$EXPR_SETUP" == "north-america" ]]; then
            SETUP="na"
          else
            SETUP="global"
          fi
          DATE=$(date +%Y.%m.%d)
          TIME=$(date +%H-%M-%S)
          BRANCH_CLEANED=$(echo "$BRANCH" | sed 's|/|-|g')
          EXPERIMENT_ID="${DATE}-${TIME}"
          SUFFIX="-${SETUP}-${BRANCH_CLEANED}-${EXPERIMENT_ID}.csv"
          echo "setup=$SETUP" >> $GITHUB_OUTPUT
          echo "experiment_id=$EXPERIMENT_ID" >> $GITHUB_OUTPUT
          echo "suffix=$SUFFIX" >> $GITHUB_OUTPUT

      - name: Run experiment multiple times
        working-directory: qa/terraform
        run: |
          terraform init
          for i in $(seq 1 $RUNS); do
            echo ">>> Starting run $i"
           
            terraform apply -auto-approve

            shopt -s expand_aliases
            source commands.sh
            mkdir -p "$HOME/.ssh"
            touch "$HOME/.ssh/known_hosts"

            deploy_cc 
            setup_config
            d_pull all
            d_run all

            EXPR_DURATION=$((EXPR_DURATION_MINUTES * 60))
            sleep "$EXPR_DURATION"

            _export_prometheus_performance_csv

            mv latency.csv latency_run_${i}.csv
            mv throughput.csv throughput_run_${i}.csv
            mv block-time.csv block-time_run_${i}.csv

            terraform destroy -auto-approve
            echo "Waiting to make sure Terraform finalized resource deletion..."
            sleep 30
          done

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload raw CSVs from all runs to S3
        working-directory: qa/terraform
        run: |
          SETUP=${{ steps.vars.outputs.setup }}
          EXPERIMENT_ID=${{ steps.vars.outputs.experiment_id }}
          for i in $(seq 1 $RUNS); do
            aws s3 cp latency_run_${i}.csv s3://malachite-performance-site/raw/$SETUP/$EXPERIMENT_ID/latency_run_${i}.csv
            aws s3 cp throughput_run_${i}.csv s3://malachite-performance-site/raw/$SETUP/$EXPERIMENT_ID/throughput_run_${i}.csv
            aws s3 cp block-time_run_${i}.csv s3://malachite-performance-site/raw/$SETUP/$EXPERIMENT_ID/block-time_run_${i}.csv
          done

      - name: Format and average CSVs across runs
        if: ${{ env.PUBLISH == 'true' }}
        working-directory: qa/terraform
        run: |
          for i in $(seq 1 $RUNS); do
            python3 scripts/format_csv_file.py block-time_run_${i}.csv --type block-time
            python3 scripts/format_csv_file.py throughput_run_${i}.csv --type throughput
          done
          python3 scripts/average_runs.py block-time_run_*.csv --output block-time.csv
          python3 scripts/average_runs.py throughput_run_*.csv --output throughput.csv

      - name: Upload formatted CSVs to dashboard folder
        if: ${{ env.PUBLISH == 'true' }}
        working-directory: qa/terraform
        run: |
          SUFFIX="${{ steps.vars.outputs.suffix }}"
          aws s3 cp block-time.csv s3://malachite-performance-site/dashboard/block-time${SUFFIX}
          aws s3 cp throughput.csv s3://malachite-performance-site/dashboard/throughput${SUFFIX}

      - name: Generate file_list.json for dashboard
        if: ${{ env.PUBLISH == 'true' }}
        working-directory: qa/terraform
        run: |
          FILES=$(aws s3api list-objects-v2 \
            --bucket malachite-performance-site \
            --query 'Contents[].Key' \
            --output json | jq -r '.[]' | grep -i '\.csv$' | grep -v 'file_list.json')

          jq -n \
            --arg base "https://malachite-performance-site.s3.us-east-1.amazonaws.com/dashboard" \
            --argjson files "$(printf '%s\n' "$FILES" | jq -R . | jq -s .)" '
            {
              baseURL: $base,
              "data-sources": {
                "block-time": ($files | map(select(test("^dashboard/block-time-.*\\.csv$"))) | map(sub("^dashboard/"; "/"))),
                "throughput": ($files | map(select(test("^dashboard/throughput-.*\\.csv$"))) | map(sub("^dashboard/"; "/")))
              }
            }
          ' > file_list.json

      - name: Upload file_list.json to S3
        if: ${{ env.PUBLISH == 'true' }}
        working-directory: qa/terraform
        run: |
          aws s3 cp file_list.json s3://malachite-performance-site/dashboard/file_list.json
