# Environment variables for the servers:
#   CANDC - the IP address of the command and control server (CC is used by compilers)
#   NODEi - the ip address of the node server "i"
#   D_N - the number of node servers in total
#   PSSH_H - space-separated list of all the node server IP addresses for pssh input
#   PSSH_P - the number of parallel processes to run with pssh
#   MALACHITE_DIR - the path to the malachite repository directory
#   IS_CC - 1 means we are on the CC server, 0 we are not. (Used to determine the docker -H parameter when run locally.)
##
# Aliases for easy manual access to the servers (don't use these in scripts)
#   ssh-cc - ssh into the cc server
#   ssh-(nodeX) - ssh into node server "X"
##
# Additional functionality in shell functions (see README for more info)
# Node name translation:
#   get_ip - Translate node ID numbers to IP addresses. 0 -> 1.2.3.4
#   get_id - Translate host names to node IDs. nyc1-1 -> 2
#   get_hostname - Translate node IDs to hostnames. 2 -> nyc1-1
# Server management:
#   xssh - Parallel SSH wrapper that uses the custom-defined PSSH_* variables.
#   ok_cc - Provide user feedback if the CC server finished building.
#   deploy_cc - Build and push the binary to CC Hub either from local machine or from CC.
#   setup_config - Create fresh default configuration for all nodes.
# Docker commands for all nodes at once:
#   d_pull - pull the node image on all the node servers.  Accepts list of IDs or "all". (example: d_pull 0 1 2)
#   d_run - run the application on a node server. Accepts list of IDs or "all". (example: d_run 0 1 2)
#   d_log - get the logs of the application from a node server (example: d_log 0 -f)
#   d_stop - stop the application on a node server. Accepts list of IDs or "all". (example: d_stop 0 2)
#   d_rm - remove node container from server. Accepts list of IDs or "all". (example: d_rm 0 1 2)
# Retrieve data:
#   cheat_sheet - get some help on the order of commands to run
#   fetch_dashboard - fetch the dashboard graphs from Grafana (example: fetch_dashboard now-30m now-15m)
#   get_prometheus_data - create a compressed prometheus data file (and download it from the cc server)
# Undocumented commands that should be made available after some more testing:
#   _change_one_config_entry
#   _reset_prometheus_db
#   _reset_elastic_db
# Undocumented commands that might become useful:
#   _reset_prometheus_db_online
#   _reset_elastic_db_online
# Undocumented commands used internally:
#   _is_cc
#   _keyscan_cc
#  _compose_persistent_peers
#  _change_config
#  _create_hostname_links
#  _parse_multiple_hosts
# Undocumented commands used for getting prometheus metrics in .csv format
# _export_prometheus_csv - export specified prometheus metric data and save it in .csv format
# _export_prometheus_performance_csv - use function above to export consensus latency and throughput 
##

# Global variables and aliases imported using jinja templates from terraform.
export CANDC="${cc.ip}"
%{~ for i, n in nodes }
export NODE${i}="${n.ip}"
%{~ endfor }
export D_N="${length(nodes)}"
export PSSH_H="${join(" ",ips)}"
%{~ for i,n in nodes }
alias ssh-node${i}="ssh -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o GlobalKnownHostsFile=/dev/null root@${n.ip}"
%{~ endfor }
export __MALACHITE_TERRAFORM_DIR="${path}"

# Global variables that change when copied to the CC server using Terraform.
export MALACHITE_DIR="$(dirname "$(dirname "$__MALACHITE_TERRAFORM_DIR")")"
export IS_CC="0"

# More global variables and aliases that can be derived from previously available data.
alias ssh-cc="ssh -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o GlobalKnownHostsFile=/dev/null root@$${CANDC}"
export PSSH_P="$${D_N}"
export PSSH_T=120
export PSSH_V="-v"

# ssh_cc runs commands on the CC server.
ssh_cc() {
  ssh -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o GlobalKnownHostsFile=/dev/null root@$${CANDC} "$@"
}

# Translate node ID numbers to IP addresses. 0 -> 1.2.3.4
get_ip() {
  case "$1" in
%{~ for i, n in nodes }
    ${i}) echo "${n.ip}";;
%{~ endfor }
    *) echo "IP for node $1 not found" && return 1
  esac
}

# Translate host names to node IDs. nyc1-1 -> 2
get_id() {
  case "$1" in
%{~ for i, n in nodes }
    ${n.name}) echo "${i}";;
%{~ endfor }
  *) echo "id for hostname $1 not found" && return 1
  esac
}

# Translate node IDs to hostnames. 2 -> nyc1-1
get_hostname() {
  case "$1" in
%{~ for i, n in nodes }
    ${i}) echo "${n.name}";;
%{~ endfor }
  *) echo "hostname for node $1 not found" && return 1
  esac
}

## End of Terraform template code. Do not put Jinja expressions below this line.
## The below code could be broken out to a separate shell script.

# Parallel SSH wrapper that uses the custom-defined PSSH_* variables.
xssh() {
  if _is_cc; then
    pssh -i $PSSH_V -p $PSSH_P -t $PSSH_T -H "$PSSH_H" "$@"
  else
    pssh -l root -O LogLevel=ERROR -O StrictHostKeyChecking=no -O UserKnownHostsFile=/dev/null -O GlobalKnownHostsFile=/dev/null -i $PSSH_V -p $PSSH_P -t $PSSH_T -H "$PSSH_H" "$@"
  fi
}

# Provide user feedback if the CC server finished building.
ok_cc() {
  PSSH_P=1 PSSH_H=$CANDC xssh "cat /etc/cc"
}

# Build and push the binary to CC Hub either from local machine or from CC.
deploy_cc() {
  test -d "$MALACHITE_DIR/code" || (echo "Source code repository not found. Clone or copy manually." && return 1)
  if _is_cc; then
    docker build --output=type=registry -t cc.testnet/node --build-context "code=$MALACHITE_DIR/code" "$MALACHITE_DIR/qa/docker"
  else
    _keyscan_cc 2> /dev/null # Needed for docker -H
    docker -H ssh://root@$CANDC build --output=type=registry -t cc.testnet/node --build-context "code=$MALACHITE_DIR/code" "$MALACHITE_DIR/qa/docker"
  fi
}

# Create fresh default configuration for all nodes.
setup_config() {
  if _is_cc; then
    rm -r /data/*
    docker run --pull always --dns $CANDC --mount type=bind,source=/data,target=/data -e RUST_LOG $CANDC/node --home /data testnet --nodes "$D_N" --deterministic
    _change_config all
    _create_hostname_links
  else
    ssh_cc "source /etc/profile.d/commands.sh && setup_config"
  fi
}

d_pull() {
  PSSH_H="$(_parse_multiple_hosts "$@")" xssh docker pull $CANDC/node
}

d_run() {
  PSSH_H="$(_parse_multiple_hosts "$@")" xssh docker run -d -p 27000:27000/tcp -p 28000:28000/tcp -p 27000:27000/udp -p 28000:28000/udp -p 9000:9000/tcp --name node --cap-add=NET_ADMIN --dns $CANDC --mount type=bind,source=/data,target=/data --mount type=bind,source=/config,target=/root/config -e RUST_LOG $CANDC/node --home /root start
}

d_log() {
  IP="$(get_ip "$1")"
  F=""
  if [ "$${1:-}" = "-f" ]; then
    F="-f"
    IP="$(get_ip "$2")"
  else
    if [ "$${2:-}" = "-f" ]; then
      F="-f"
    fi
  fi
  ssh -A -o LogLevel=ERROR -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o GlobalKnownHostsFile=/dev/null root@$IP docker logs $F node
}

d_stop() {
  PSSH_H="$(_parse_multiple_hosts "$@")" xssh docker stop node
}

d_rm() {
  PSSH_H="$(_parse_multiple_hosts "$@")" xssh "docker stop node 2> /dev/null; docker rm node"
}

cheat_sheet() {
cat <<EOF
deploy_cc
ssh-cc
setup_config
d_pull all
d_run all
(wait for data)
d_stop all
fetch_dashboard
get_prometheus_data
d_rm all
_reset_prometheus_db
EOF
}

get_prometheus_data() {
  if _is_cc; then
    rm -f prometheus.tgz
    docker stop prometheus && tar -cvzf prometheus.tgz -C /var/lib/docker/volumes/docker_prometheus/_data .
    docker start prometheus
  else
    ssh_cc "rm -f prometheus.tgz; docker stop prometheus && tar -cvzf prometheus.tgz -C /var/lib/docker/volumes/docker_prometheus/_data . ; docker start prometheus"
    scp -r "root@$CANDC:prometheus.tgz" .
  fi
}

_reset_prometheus_db() {
  if _is_cc; then
    docker stop prometheus
    rm -rf /var/lib/docker/volumes/docker_prometheus/_data/*
    docker start prometheus
  else
    ssh_cc "docker stop prometheus && rm -rf /var/lib/docker/volumes/docker_prometheus/_data/*; docker start prometheus"
  fi
}

_reset_prometheus_db_online() {
  # Mark all node_exporter data for deletion
  #curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/delete_series?match[]={job="node_exporter"}'
  # Mark all malachite data for deletion
  #curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/delete_series?match[]={job="malachite"}'
  # Mark all data for deletion
  #curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/delete_series?match[]={__name__=~".+"}'
  # Set end of deletion frame to "now - 30 minutes".
  END="$1"
  if [ -z "$END" ]; then
    END="$(($(date +%s) - 60 * 30))"
  fi
  # Mark node_exporter data for deletion
  curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/delete_series?match[]={job="node_exporter"}&end='"$END"
  # Mark malachite data for deletion
  curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/delete_series?match[]={job="malachite"}&end='"$END"
  # Physically delete data
  curl -s -X POST -g 'http://$${CANDC}:9090/api/v1/admin/tsdb/clean_tombstones'
}

_reset_elastic_db() {
  if _is_cc; then
    docker stop docker-elk-elasticsearch-1
    rm -rf /var/lib/docker/volumes/docker-elk_elasticsearch/_data/*
    docker start docker-elk-elasticsearch-1
  else
    ssh_cc "docker stop docker-elk-elasticsearch-1 && rm -rf /var/lib/docker/volumes/docker-elk_elasticsearch/_data/*; docker start docker-elk-elasticsearch-1"
  fi
}

_reset_elastic_db_online() {
  if [ -f /root/docker-elk/.env ]; then
    source /root/docker-elk/.env
  fi
  if [ -z "$ELASTIC_PASSWORD" ]; then
    echo "Please set the ELASTIC_PASSWORD environment variable."
  else
    INDEX="$(curl -s -X GET --user "elastic:$ELASTIC_PASSWORD" http://$${CANDC}:9200/_cat/indices/*docker* | cut -d\  -f3)"
    DS="$(echo $INDEX | sed -e 's/^.ds-logs-//' -e 's/-[^-]*$//')"
    curl -X DELETE --user "elastic:$ELASTIC_PASSWORD" "http://$${CANDC}:9200/_data_stream/$DS"
    curl -X DELETE --user "elastic:$ELASTIC_PASSWORD" "http://$${CANDC}:9200/$INDEX"
  fi
}

_is_cc() {
  return $((1 - IS_CC))
}

_keyscan_cc() {
  mkdir -p "$HOME/.ssh"
  touch "$HOME/.ssh/known_hosts"
  ssh-keygen -R "$CANDC" > /dev/null
  ssh-keyscan -t ed25519 "$CANDC" >> "$HOME/.ssh/known_hosts"
}

_compose_persistent_peers() {
  skip=$${1:-10000}
  port=$${2:-27000}
  transport_protocol=$${3:-tcp}

  persistent_peers=""
  for i in $(seq 0 $((D_N-1)))
  do
    if [ "$i" -eq "$skip" ]; then
      continue
    fi
    if [ "$transport_protocol" == "quic" ]; then
      persistent_peers="$persistent_peers,/dns/node$i/udp/$port/quic-v1"
    else
      persistent_peers="$persistent_peers,/dns/node$i/tcp/$port"
    fi
  done
  echo $${persistent_peers##,}
}

_change_config() {
  P="$@"
  if [ "$P" = "all" ]; then
    P="$(seq 0 $((D_N-1)))"
  fi
  for i in $P
  do
    file="/data/$i/config/config.toml"
    sconfig "$file" \
      "moniker=test-$i" \
      "consensus.p2p.listen_addr=/ip4/0.0.0.0/tcp/27000" \
      "consensus.p2p.transport=tcp" \
      "consensus.p2p.discovery.enabled=true" \
      "mempool.p2p.listen_addr=/ip4/0.0.0.0/tcp/28000" \
      "mempool.p2p.transport=tcp" \
      "mempool.p2p.discovery.enabled=true" \
      "metrics.listen_addr=0.0.0.0:9000" \
      "runtime.flavor=single_threaded" \
      "logging.log_format=json" && \
    sconfig "$file" -t stringSlice \
      "consensus.p2p.persistent_peers=$(_compose_persistent_peers $i 27000 tcp)" \
      "mempool.p2p.persistent_peers=$(_compose_persistent_peers $i 28000 tcp)" && \
    sconfig "$file" -t int \
      "runtime.worker_threads=0" \
      "mempool.load.count=1000"
    sconfig "$file" \
      "test.exec_time_per_tx=0ms" \
      "mempool.load.interval=100ms" \
      "mempool.load.size=1 KB" \
      "consensus.timeout_propose=10s" \
      "consensus.timeout_prevote=5s" \
      "consensus.timeout_precommit=5s" 
  done
}

_change_one_config_entry() {
  P="$(seq 0 $((D_N-1)))"
  for i in $P
  do
    file="/data/$i/config/config.toml"
    sconfig "$file" "$@"
  done
}

_create_hostname_links() {
  P="$(seq 0 $((D_N-1)))"
  for i in $P
  do
    H=$(get_hostname $i)
    ln -sf /data/$i /data/$H
  done
}

_parse_multiple_hosts() {
  PSSH_X=""
  if [ "$1" = "all" ] || [ $# -eq 0 ]; then
    PSSH_X="$PSSH_H"
  else
    while (( "$#" ));
    do
      case "$1" in
          ''|*[!0-9]*) echo "Invalid number $1, skipping..." ;;
          *) PSSH_X="$PSSH_X $(get_ip "$1")" ;;
      esac
      shift
    done
  fi
  echo "$PSSH_X"
}

fetch_dashboard() {
  FROM="$${1:-now-15m}"
  TO="$${2:-now}"

  WIDTH="$${WIDTH:-1000}"
  HEIGHT="$${HEIGHT:-500}"
  SCALE="$${SCALE:-1}"
  TZ="$${TZ:-America/Toronto}"
  TIMEZONE="$(echo "$TZ" | sed 's,/,%2F,g')"

  for i in $(seq 1 30)
  do
    wget -O "$i.png" "http://$${CANDC}:3000/render/d-solo/fdo24nq8yvf28f/malachite-first-stab?from=$FROM&to=$TO&panelId=$i&width=$WIDTH&height=$HEIGHT&scale=$SCALE&tz=$TIMEZONE"
  done
}


_export_prometheus_csv() {
  local METRIC_QUERY="$1"         # PromQL expression
  local OUTPUT="$2"               # output file name, e.g., "throughput.csv"
  local STEP="$${3:-5}"
  local LAST_MINUTES="$${4:-10}"  # default to last 10 minutes if not provided

  local END=$(date +%s)
  local START=$((END - LAST_MINUTES * 60))

  local PROM_HOST
  if _is_cc; then
    PROM_HOST="localhost"
  else
    PROM_HOST="$CANDC"
  fi

  echo "Querying $METRIC_QUERY from $PROM_HOST, output to $OUTPUT (last $LAST_MINUTES minutes)..."

  curl -sG "http://$PROM_HOST:9090/api/v1/query_range" \
    --data-urlencode "query=$METRIC_QUERY" \
    --data-urlencode "start=$START" \
    --data-urlencode "end=$END" \
    --data-urlencode "step=$STEP" | jq -r '
      .data.result[]? | .metric as $m | .values[] |
      [$m.instance, .[0], .[1]] | @csv
    ' > "$OUTPUT"

  echo "Exported to $OUTPUT"
}


_export_prometheus_performance_csv() {

  _export_prometheus_csv \
  'rate(malachitebft_core_consensus_finalized_txes_total[30s])' \
  throughput.csv \
  30 \
  10

  _export_prometheus_csv \
  'increase(malachitebft_core_consensus_consensus_time_sum[30s]) / increase(malachitebft_core_consensus_consensus_time_count[30s])' \
  latency.csv \
  30 \
  10

  _export_prometheus_csv \
  'increase(malachitebft_core_consensus_time_per_block_sum[30s]) / increase(malachitebft_core_consensus_time_per_block_count[30s])' \
  block-time.csv \
  30 \
  10

}